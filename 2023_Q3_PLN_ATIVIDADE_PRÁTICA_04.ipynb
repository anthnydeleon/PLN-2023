{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anthnydeleon/PLN-2023/blob/main/2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 04 [Uso da API da OpenAI com técnicas de PLN]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 04** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/GzwCq3R7ExtE9g9a8\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia 20/11 (segunda-feira) APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Anthony Deleon de Almeida Costa 11202131250`\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Pedro Henrique Dias Pereira 11202130640`\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "`Ulisses Eduardo Zorzan Braz 11202130417`"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: 1`\n",
        "\n",
        "`Segundo capítulo: 24`\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso da **API da OpenAI** aplicando, no mínimo, 3 técnicas de PLN. As técnicas devem ser aplicadas nos 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        ">\n",
        "\n",
        "**RESTRIÇÃO**: É obrigatório usar o *endpoint* \"*`Chat Completions`*\".\n",
        "\n",
        ">\n",
        "\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   **Similaridade de Textos**\n",
        "*   **Reconhecimento de Entidades Nomeadas**\n",
        "*   **Sistemas de Perguntas e Respostas**\n",
        "\n",
        ">\n",
        "\n",
        "Os capítulos devem ser os mesmos selecionados na **ATIVIDADE PRÁTICA 02**. Para consultar os capítulos, considere a seguinte planilha:\n",
        "\n",
        ">\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC. Não é permitido alterar os capítulos já selecionados.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão considerados como critérios de avaliação as técnicas usadas e a criatividade envolvida na aplicação das mesmas.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuração da API"
      ],
      "metadata": {
        "id": "IX-Q-YsSNsXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Instalando a biblioteca da API da OpenAI\n",
        "\n",
        "# Listagem 1.1 - Instalação do pacote Python da API da OpenAI\n",
        "\n",
        "print(f\"Instalando a biblioteca da API da OpenAI...\")\n",
        "\n",
        "!pip install openai==0.28.1\n",
        "\n",
        "print(\"API da OpenAI instalada!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca_dz2h7UtqS",
        "outputId": "68e74337-69e8-4c49-ae86-6d74b15af6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando a biblioteca da API da OpenAI...\n",
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n",
            "API da OpenAI instalada!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Versão da API da OpenAI\n",
        "\n",
        "import openai\n",
        "\n",
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKcH0xzyU-8V",
        "outputId": "1b7fbf00-92fa-42a8-a8d3-4deffb56563e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Definindo a chave da API\n",
        "\n",
        "# Listagem 1.5 - Configuração da chave de acesso da API a partir do upload de um arquivo de texto\n",
        "\n",
        "import openai\n",
        "from google.colab import files\n",
        "\n",
        "# fazer upload do arquivo de texto\n",
        "upload_arquivo = files.upload()\n",
        "\n",
        "# obter o nome do arquivo\n",
        "nome_arquivo = list(upload_arquivo.keys())[0]\n",
        "\n",
        "# ler apenas a primeira linha do arquivo\n",
        "with open(nome_arquivo, 'r') as file:\n",
        "    chave_api = file.readline().strip()  # Utilizando readline() para ler apenas a primeira linha\n",
        "\n",
        "# definir a chave da API\n",
        "openai.api_key = chave_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "6s9JzfEHV_ys",
        "outputId": "a091e5e0-d46d-4bd4-d5ab-e59ca0b488cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ecd9e5ff-8cb4-4bcc-99cf-2f0f038461ea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ecd9e5ff-8cb4-4bcc-99cf-2f0f038461ea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving apikey.txt to apikey.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requisição HTTP"
      ],
      "metadata": {
        "id": "T-PmxNPsNH2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBS**: Estamos salvando cada capitulo em um arquivo txt para facilitar a aplicação das técnicas de PLN"
      ],
      "metadata": {
        "id": "Ylw4G63tNQth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Request\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "import os\n",
        "\n",
        "class GetWebBookContent:\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "        self.request_data = None\n",
        "        self.content_page = None\n",
        "\n",
        "    def process(self):\n",
        "        # Método principal para processar a página web\n",
        "        print(f\"\\nSolicitando url: {self.url}\")\n",
        "        try:\n",
        "            self._get_data()\n",
        "            self._get_main_content()\n",
        "            return self.content_page\n",
        "        except Exception as e:\n",
        "            print(f\"Erro durante o processamento: {e}\")\n",
        "            return None\n",
        "\n",
        "    def _get_data(self):\n",
        "        # Método privado para obter dados da página\n",
        "        user_agents = [\n",
        "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
        "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/16.16299\",\n",
        "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Firefox/58.0\",\n",
        "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/602.4.8 (KHTML, like Gecko) Version/10.0.3 Safari/602.4.8\",\n",
        "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36\",\n",
        "        ]\n",
        "        headers = {'User-Agent': random.choice(user_agents)}\n",
        "        data = requests.get(self.url, headers=headers)\n",
        "        data.raise_for_status()\n",
        "        self.request_data = data\n",
        "\n",
        "    def _get_main_content(self):\n",
        "        # Método privado para obter o conteúdo principal da página\n",
        "        soup = BeautifulSoup(self.request_data.content, 'html.parser')\n",
        "        level2_sections = soup.find_all(\"section\", {\"class\": \"level2\"})\n",
        "\n",
        "        # Exclui as divs dentro da section com a classe 'references'\n",
        "        for section in level2_sections:\n",
        "            for references_div in section.find_all(\"div\", {\"class\": \"references\"}):\n",
        "                references_div.decompose()\n",
        "\n",
        "        # Extrai o conteúdo de cada seção e concatena\n",
        "        self.content_page = \"\\n\".join([section.text for section in level2_sections])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Parte principal do script\n",
        "    print(\"Iniciando requisição ...\")\n",
        "\n",
        "    urls = [\n",
        "        \"https://brasileiraspln.com/livro-pln/1a-edicao/parte1/cap1/cap1.html\",\n",
        "        \"https://brasileiraspln.com/livro-pln/1a-edicao/parte10/cap24/cap24.html\",\n",
        "    ]\n",
        "\n",
        "    for url in urls:\n",
        "        pr = GetWebBookContent(url)\n",
        "        content = pr.process()\n",
        "\n",
        "        if content is not None:\n",
        "            filename = os.path.splitext(os.path.basename(url))[0] + \".txt\"\n",
        "\n",
        "            with open(filename, 'w', encoding='utf-8') as file:\n",
        "                file.write(content)\n",
        "                print(f\"Conteúdo da página salvo em {filename}\")\n",
        "\n",
        "    print(\"\\n\\nArquivos salvos e prontos para uso.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAY6S1K622yi",
        "outputId": "dc808dd7-24c3-408d-8108-b06a000292b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando requisição ...\n",
            "\n",
            "Solicitando url: https://brasileiraspln.com/livro-pln/1a-edicao/parte1/cap1/cap1.html\n",
            "Conteúdo da página salvo em cap1.txt\n",
            "\n",
            "Solicitando url: https://brasileiraspln.com/livro-pln/1a-edicao/parte10/cap24/cap24.html\n",
            "Conteúdo da página salvo em cap24.txt\n",
            "\n",
            "\n",
            "Arquivos salvos e prontos para uso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Técnicas de PLN"
      ],
      "metadata": {
        "id": "FEVaRQu1L7j0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Tradução de texto\n",
        "    - Como cada capitulo tem muitos tokens, utilizamos um modelo (gpt-3.5-turbo-16k) que comportasse o tamanho do prompt, então pode demorar para solicitar a tradução do arquivo.\n",
        "    - Optamos por deixar a tradução salva em um arquivo txt, pois devido seu tamanho, ficaria muito ruim de ser visualizado no output\n",
        "- Extração de palavras-chave\n",
        "- Sumarização de texto"
      ],
      "metadata": {
        "id": "KcBIY1TFMEbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Tradução de texto\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import openai  # Adicione esta linha\n",
        "\n",
        "def traducao(texto, idioma):\n",
        "    mensagens = [\n",
        "        {\"role\": \"system\", \"content\": \"Você é um assistente de tradução.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Traduza o seguinte texto para o idioma {idioma}: {texto}\"},\n",
        "    ]\n",
        "\n",
        "    resposta = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=mensagens\n",
        "    )\n",
        "\n",
        "    return resposta['choices'][0]['message']['content']\n",
        "\n",
        "def webscrape(capitulo: str, parte: str):\n",
        "    print(f'pegando informações sobre o capítulo {capitulo}...')\n",
        "    capitulo_url = f'https://brasileiraspln.com/livro-pln/1a-edicao/parte{parte}/cap{capitulo}/cap{capitulo}.html'\n",
        "\n",
        "    try:\n",
        "        page = requests.get(capitulo_url)\n",
        "        page.raise_for_status()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f'Erro ao obter {e}')\n",
        "        return None\n",
        "\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    # Correção aqui\n",
        "    texto = soup.select('.level2')\n",
        "    # Correção aqui\n",
        "    texto_limpo = ' '.join([p.get_text() for p in texto])\n",
        "\n",
        "    return texto_limpo\n",
        "\n",
        "def informacoes_limpas():\n",
        "    capitulos_partes = [['1', '1'], ['24', '10']]\n",
        "    texto_completo = []\n",
        "\n",
        "    for capitulo_parte in capitulos_partes:\n",
        "        texto_completo.append(webscrape(capitulo_parte[0], capitulo_parte[1]))\n",
        "\n",
        "    return texto_completo\n",
        "\n",
        "# Idioma para tradução\n",
        "idioma = \"inglês\"\n",
        "\n",
        "# Obter o texto completo\n",
        "texto_completo = informacoes_limpas()\n",
        "\n",
        "# Criar diretório de saída\n",
        "diretorio_saida = 'capitulos_traduzidos'\n",
        "if not os.path.exists(diretorio_saida):\n",
        "    os.makedirs(diretorio_saida)\n",
        "\n",
        "capitulos = ['1', '24']\n",
        "# Traduzir cada parte do texto e escrever em arquivos\n",
        "for i, parte in enumerate(texto_completo):\n",
        "    resultado_traducao = traducao(parte, idioma)\n",
        "\n",
        "    # Criar nome do arquivo\n",
        "    nome_arquivo = os.path.join(diretorio_saida, f'capitulo_{capitulos[i]}.txt')\n",
        "\n",
        "    # Escrever tradução no arquivo\n",
        "    with open(nome_arquivo, 'w', encoding='utf-8') as arquivo_saida:\n",
        "        arquivo_saida.write(resultado_traducao)\n",
        "\n",
        "    print(f'Tradução do capítulo {capitulos[i]} salva em: {nome_arquivo}')\n"
      ],
      "metadata": {
        "id": "-WaZexr727n2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb31f54-8cf2-461f-8381-57a2c9057d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pegando informações sobre o capítulo 1...\n",
            "pegando informações sobre o capítulo 24...\n",
            "Tradução do capítulo 1 salva em: capitulos_traduzidos/capitulo_1.txt\n",
            "Tradução do capítulo 24 salva em: capitulos_traduzidos/capitulo_24.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Extração de Palavras-chave\n",
        "\n",
        "import os\n",
        "import openai\n",
        "import re\n",
        "\n",
        "def formatar_saida(saida):\n",
        "    return re.sub(r'^\\s+', '', saida)\n",
        "\n",
        "# Define a função para extrair palavras-chaves de um texto\n",
        "def extracao_palavras_chaves(texto):\n",
        "    resposta = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Extraia 20 palavras-chave do seguinte texto:\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{texto}\"},\n",
        "        ]\n",
        "    )\n",
        "    return formatar_saida(resposta['choices'][0]['message']['content'])\n",
        "\n",
        "# Define a função para processar a extração de palavra-chave de arquivos\n",
        "def leitura_do_arquivo(diretorio):\n",
        "    # Lista de arquivos no diretório\n",
        "    arquivos = [\"cap1.txt\", \"cap24.txt\"]\n",
        "\n",
        "    # Lista para armazenar resultados\n",
        "    resultados = []\n",
        "\n",
        "    # Loop através dos arquivos\n",
        "    for arquivo in arquivos:\n",
        "        caminho_arquivo = os.path.join(diretorio, arquivo)\n",
        "\n",
        "        # Lê o conteúdo do arquivo\n",
        "        with open(caminho_arquivo, \"r\", encoding=\"utf-8\") as f:\n",
        "            conteudo = f.read()\n",
        "\n",
        "        # Aplica a extração de palavra-chave do conteúdo\n",
        "        resultado = extracao_palavras_chaves(conteudo)\n",
        "\n",
        "        # Adiciona o resultado à lista\n",
        "        resultados.append(resultado)\n",
        "\n",
        "        # Imprime ou faz algo com o resultado\n",
        "        print(f\"\\nPalavras-chave do arquivo {arquivo}: \\n {resultado} \\n\")\n",
        "\n",
        "    # Retorna a lista de resultados (opcional, dependendo do uso)\n",
        "    return resultados\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    diretorio_arquivos = \".\"  # Diretório onde os arquivos estão salvos\n",
        "\n",
        "    # Chama a função e captura os resultados, se necessário\n",
        "    resultados = leitura_do_arquivo(diretorio_arquivos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_W_9zIP_-ju",
        "outputId": "3b62146b-0607-401a-a63f-73cd540be758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Palavras-chave do arquivo cap1.txt: \n",
            " 1. Processamento de Linguagem Natural\n",
            "2. Campo de pesquisa\n",
            "3. Linguagens humanas\n",
            "4. Línguas faladas e escritas\n",
            "5. Inteligência Artificial\n",
            "6. Linguística Computacional\n",
            "7. Interpretação de Linguagem Natural\n",
            "8. Geração de Linguagem Natural\n",
            "9. Línguas de sinais\n",
            "10. Reconhecimento de sentimentos\n",
            "11. Língua escrita\n",
            "12. Língua oral\n",
            "13. Chatbots\n",
            "14. Respostas automatizadas\n",
            "15. Redes Neurais Profundas\n",
            "16. Paradigma simbólico\n",
            "17. Paradigma estatístico\n",
            "18. Paradigma neural\n",
            "19. Paradigmas híbridos\n",
            "20. Mineração de textos \n",
            "\n",
            "\n",
            "Palavras-chave do arquivo cap24.txt: \n",
            " 1. Ética em IA\n",
            "2. Tecnologia de IA\n",
            "3. Algoritmos de aprendizado\n",
            "4. Dados desbalanceados\n",
            "5. Vieses algorítmicos\n",
            "6. Discriminação racial\n",
            "7. Justiça social\n",
            "8. Transparência e explicabilidade\n",
            "9. Robustez técnica e segurança\n",
            "10. Privacidade e proteção de dados\n",
            "11. Responsabilidade e prestação de contas\n",
            "12. Viés linguístico\n",
            "13. Inclusão linguística\n",
            "14. Propriedade intelectual e direitos autorais\n",
            "15. Chatbots\n",
            "16. Geração de linguagem natural\n",
            "17. Autenticidade e veracidade\n",
            "18. Riscos da IA\n",
            "19. Desenvolvimento ético de sistemas de IA\n",
            "20. Debates sobre impactos da IA \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Sumarização de texto\n",
        "\n",
        "import os\n",
        "import openai\n",
        "\n",
        "\n",
        "# Define a função para extrair palavras-chaves de um texto\n",
        "def sumarizacao(texto):\n",
        "    resposta = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Sumarize o texto a seguir em poucas frases:\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{texto}\"},\n",
        "        ]\n",
        "    )\n",
        "    return resposta['choices'][0]['message']['content']\n",
        "\n",
        "# Define a função para processar a sumarização dos arquivos\n",
        "def leitura_do_arquivo(diretorio):\n",
        "    # Lista de arquivos no diretório\n",
        "    arquivos = [\"cap1.txt\", \"cap24.txt\"]\n",
        "\n",
        "    # Lista para armazenar resultados\n",
        "    resultados = []\n",
        "\n",
        "    # Loop através dos arquivos\n",
        "    for arquivo in arquivos:\n",
        "        caminho_arquivo = os.path.join(diretorio, arquivo)\n",
        "\n",
        "        # Lê o conteúdo do arquivo\n",
        "        with open(caminho_arquivo, \"r\", encoding=\"utf-8\") as f:\n",
        "            conteudo = f.read()\n",
        "\n",
        "        # Aplica a sumarizacao do conteúdo\n",
        "        resultado = sumarizacao(conteudo)\n",
        "\n",
        "        # Adiciona o resultado à lista\n",
        "        resultados.append(resultado)\n",
        "\n",
        "        # Imprime ou faz algo com o resultado\n",
        "        print(f\"\\nSumarização do {arquivo}: \\n{resultado}\")\n",
        "\n",
        "    # Retorna a lista de resultados (opcional, dependendo do uso)\n",
        "    return resultados\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    diretorio_arquivos = \".\"  # Diretório onde os arquivos estão salvos\n",
        "\n",
        "    # Chama a função e captura os resultados, se necessário\n",
        "    resultados = leitura_do_arquivo(diretorio_arquivos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl_DMgulI97N",
        "outputId": "68470041-04c0-48ff-e21a-96ec22b7e9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sumarização do cap1.txt: \n",
            "O texto apresenta uma introdução ao Processamento de Linguagem Natural (PLN), que é o campo de pesquisa que investiga e propõe métodos e sistemas de processamento computacional da linguagem humana. O PLN é dividido nas subáreas de Interpretação de Linguagem Natural (NLU) e Geração de Linguagem Natural (NLG). O texto também explora os conceitos de aplicações, recursos e ferramentas em PLN. Além disso, são destacados os paradigmas de PLN, como o simbólico, estatístico e neural. Por fim, são feitas considerações sobre as limitações e desafios do PLN, como a complexidade da linguagem natural e a representação semântica.\n",
            "\n",
            "Sumarização do cap24.txt: \n",
            "O texto discute a importância da ética na inteligência artificial (IA), destacando que o treinamento dos algoritmos de IA com dados desbalanceados e sem curadoria pode resultar em vieses e comportamentos indesejáveis. São citados casos de discriminação racial e de influência da IA em eleições. Além disso, é abordada a falta de transparência e explicabilidade dos algoritmos de IA, o que gera insegurança e desconfiança. O texto também destaca a necessidade de regulamentação e princípios éticos para garantir a justiça, diversidade, não discriminação, transparência, segurança e proteção de dados na IA. No contexto do Processamento de Linguagem Natural (PLN), o texto ressalta a importância de considerar a diversidade linguística e cultural e a responsabilidade na coleta de dados para treinamento de modelos de linguagem. Por fim, é enfatizado que os modelos de linguagem não têm compreensão do texto gerado e podem apresentar informações incorretas ou enviesadas, o que levanta questões éticas no uso desses sistemas.\n"
          ]
        }
      ]
    }
  ]
}